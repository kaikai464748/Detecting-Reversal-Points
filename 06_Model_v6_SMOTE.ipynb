{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d63651b9-4b32-4568-aecb-0b13f519bc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "import gc # åƒåœ¾å›æ”¶import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter # ç”¨äºæ£€æŸ¥ç±»åˆ«åˆ†å¸ƒ\n",
    "# ğŸ’¡ æ–°å¢ï¼šå¯¼å…¥ SMOTENC (ç”¨äºå¤„ç†ç±»åˆ«ç‰¹å¾ ticker_id)\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "\n",
    "# è®¾ç½® Matplotlib/Seaborn æ ·å¼\n",
    "sns.set(style='whitegrid')\n",
    "# è®¾ç½® Pandas æ˜¾ç¤ºé€‰é¡¹\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfde2986-acfb-4d3a-8292-d3129780f907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ­£åœ¨åŠ è½½ç‰¹å¾åŒ–è®­ç»ƒæ•°æ® (train_with_features.csv)...\n",
      "æ•°æ®åŠ è½½æˆåŠŸï¼å½¢çŠ¶: (1932, 68736)\n",
      "æ­£åœ¨æ¢å¤æ•°æ®ç±»å‹...\n",
      "æ•°æ®ç±»å‹æ¢å¤å®Œæ¯•ã€‚\n"
     ]
    }
   ],
   "source": [
    "print(\"æ­£åœ¨åŠ è½½ç‰¹å¾åŒ–è®­ç»ƒæ•°æ® (train_with_features.csv)...\")\n",
    "try:\n",
    "    df_train = pd.read_csv('train_with_features.csv', low_memory=False)\n",
    "    print(f\"æ•°æ®åŠ è½½æˆåŠŸï¼å½¢çŠ¶: {df_train.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"é”™è¯¯ï¼štrain_with_features.csv æ–‡ä»¶æœªæ‰¾åˆ°ã€‚\")\n",
    "    raise# æ¢å¤æ•°æ®ç±»å‹\n",
    "print(\"æ­£åœ¨æ¢å¤æ•°æ®ç±»å‹...\")\n",
    "df_train['t'] = pd.to_datetime(df_train['t'])\n",
    "df_train['ticker_id'] = df_train['ticker_id'].astype('category')\n",
    "print(\"æ•°æ®ç±»å‹æ¢å¤å®Œæ¯•ã€‚\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "729ae82c-6380-4c7d-a79e-938ca1549f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ç›®æ ‡å˜é‡ç¼–ç å®Œæˆã€‚\n",
      "class_label_encoded\n",
      "0      40\n",
      "1      28\n",
      "2      18\n",
      "3      26\n",
      "4    1820\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 1. å®šä¹‰ 5 åˆ†ç±»ç›®æ ‡æ˜ å°„\n",
    "target_map = {'HH': 0, 'HL': 1, 'LH': 2, 'LL': 3}\n",
    "df_train['class_label_encoded'] = df_train['class_label'].map(target_map)\n",
    "df_train['class_label_encoded'] = df_train['class_label_encoded'].fillna(4)\n",
    "df_train['class_label_encoded'] = df_train['class_label_encoded'].astype(int)\n",
    "\n",
    "print(\"ç›®æ ‡å˜é‡ç¼–ç å®Œæˆã€‚\")\n",
    "print(df_train['class_label_encoded'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "064fa5c7-f6cc-4011-a901-685961dd48a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model v6 (SMOTE) ç‰¹å¾é€‰æ‹© ---\n",
      "SMOTE å°†åœ¨ 300 ä¸ª Top ç‰¹å¾ä¸Šè¿è¡Œã€‚\n"
     ]
    }
   ],
   "source": [
    "# 1. å®šä¹‰ç›®æ ‡å’Œå…ƒæ•°æ®\n",
    "TARGET = 'class_label_encoded'\n",
    "METADATA_COLS = ['class_label', 'class_label_encoded', 't', 'id', 'train_id']\n",
    "\n",
    "# 2. åŠ è½½ V2 æ¨¡å‹çš„ç‰¹å¾é‡è¦æ€§\n",
    "try:\n",
    "    importance_df = pd.read_csv('feature_importance_v2.csv')\n",
    "except FileNotFoundError:\n",
    "    print(\"é”™è¯¯ï¼š'feature_importance_v2.csv' æœªæ‰¾åˆ°ï¼\")\n",
    "    print(\"è¯·è¿”å› 03_Model_v2... ç¬”è®°æœ¬ï¼Œè¿è¡Œ CELL 8 ä»¥ä¿å­˜è¯¥æ–‡ä»¶ã€‚\")\n",
    "    raise# 3. å®šä¹‰æˆ‘ä»¬çš„â€œç²¾è‹±ç‰¹å¾é›†â€ (ä¸ V3 ç›¸åŒ)\n",
    "NUM_TOP_FEATURES = 300\n",
    "top_features = importance_df.head(NUM_TOP_FEATURES)['feature'].tolist()\n",
    "\n",
    "# 4. ç¡®ä¿ 'ticker_id' è¢«åŒ…å«åœ¨å†…\n",
    "if 'ticker_id' not in top_features:\n",
    "    top_features.append('ticker_id')\n",
    "\n",
    "# 5. å°†æ­¤åˆ—è¡¨è®¾ç½®ä¸ºæˆ‘ä»¬çš„æœ€ç»ˆ FEATURES\n",
    "FEATURES = top_features\n",
    "\n",
    "print(f\"--- Model v6 (SMOTE) ç‰¹å¾é€‰æ‹© ---\")\n",
    "print(f\"SMOTE å°†åœ¨ {len(FEATURES)} ä¸ª Top ç‰¹å¾ä¸Šè¿è¡Œã€‚\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03715305-86d9-49f9-b858-2cd8590bf69a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ­£åœ¨æŒ‰ 't' å’Œ 'ticker_id' æ’åºæ•°æ®ä»¥è¿›è¡ŒéªŒè¯åˆ†å‰²...\n",
      "æ–°è®­ç»ƒé›†æ ·æœ¬æ•°: 1545, æ–°éªŒè¯é›†æ ·æœ¬æ•°: 387\n",
      "æ­£åœ¨ä¿®å¤ 'object' æ•°æ®ç±»å‹å¹¶å¡«å…… NaN...\n",
      "å·²å°† 299 ä¸ªç‰¹å¾åˆ—å¼ºåˆ¶è½¬æ¢ä¸ºæ•°å€¼ç±»å‹ã€‚\n",
      "æ­£åœ¨ç”¨ -999 å¡«å……å‰©ä½™çš„ NaN å€¼ (ä»…æ•°å€¼åˆ—)...\n",
      "NaN å¡«å……å®Œæ¯•ï¼\n",
      "éªŒè¯é›†åˆ›å»ºå®Œæ¯•ï¼\n"
     ]
    }
   ],
   "source": [
    "# 1. ç¡®ä¿æ•°æ®ä¸¥æ ¼æŒ‰æ—¶é—´æ’åº\n",
    "print(\"æ­£åœ¨æŒ‰ 't' å’Œ 'ticker_id' æ’åºæ•°æ®ä»¥è¿›è¡ŒéªŒè¯åˆ†å‰²...\")\n",
    "df_train = df_train.sort_values(by=['t', 'ticker_id']).reset_index(drop=True)\n",
    "\n",
    "# 2. å®šä¹‰ 80/20 åˆ†å‰²ç‚¹\n",
    "split_percentage = 0.8\n",
    "split_index = int(len(df_train) * split_percentage)\n",
    "\n",
    "# 3. åˆ†å‰²æ•°æ®\n",
    "train_data = df_train.iloc[:split_index]\n",
    "val_data = df_train.iloc[split_index:]\n",
    "print(f\"æ–°è®­ç»ƒé›†æ ·æœ¬æ•°: {len(train_data)}, æ–°éªŒè¯é›†æ ·æœ¬æ•°: {len(val_data)}\")\n",
    "\n",
    "# 4. åˆ›å»º X (ç‰¹å¾) å’Œ y (ç›®æ ‡) (åªä½¿ç”¨ Top 300 ç‰¹å¾)\n",
    "X_train = train_data[FEATURES]\n",
    "y_train = train_data[TARGET]\n",
    "X_val = val_data[FEATURES]\n",
    "y_val = val_data[TARGET]\n",
    "\n",
    "# 5. ä¿®å¤æ•°æ®ç±»å‹ å’Œ å¡«å…… NaN\n",
    "print(\"æ­£åœ¨ä¿®å¤ 'object' æ•°æ®ç±»å‹å¹¶å¡«å…… NaN...\")\n",
    "# æ‰¾å‡º 'ticker_id' ä¹‹å¤–çš„æ‰€æœ‰ç‰¹å¾åˆ—\n",
    "numeric_features = [col for col in FEATURES if col != 'ticker_id']\n",
    "\n",
    "# æˆ‘ä»¬ä½¿ç”¨ .copy() æ¥é¿å… Pandas çš„ SettingWithCopyWarning\n",
    "X_train_copy = X_train.copy()\n",
    "X_val_copy = X_val.copy()\n",
    "\n",
    "for col in numeric_features:\n",
    "    # å¼ºåˆ¶è½¬æ¢ä¸ºæ•°å€¼ç±»å‹\n",
    "    X_train_copy[col] = pd.to_numeric(X_train_copy[col], errors='coerce', downcast='float')\n",
    "    X_val_copy[col] = pd.to_numeric(X_val_copy[col], errors='coerce', downcast='float')\n",
    "\n",
    "# æ›¿æ¢å›åŸæ¥çš„å˜é‡\n",
    "X_train = X_train_copy\n",
    "X_val = X_val_copy\n",
    "print(f\"å·²å°† {len(numeric_features)} ä¸ªç‰¹å¾åˆ—å¼ºåˆ¶è½¬æ¢ä¸ºæ•°å€¼ç±»å‹ã€‚\")\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# ğŸ’¡ ã€é”™è¯¯ä¿®å¤ã€‘ åªå¯¹ numeric_features åˆ—è¿›è¡Œ fillna\n",
    "# ----------------------------------------------------\n",
    "print(\"æ­£åœ¨ç”¨ -999 å¡«å……å‰©ä½™çš„ NaN å€¼ (ä»…æ•°å€¼åˆ—)...\")\n",
    "X_train[numeric_features] = X_train[numeric_features].fillna(-999)\n",
    "X_val[numeric_features] = X_val[numeric_features].fillna(-999)\n",
    "print(\"NaN å¡«å……å®Œæ¯•ï¼\")\n",
    "# ----------------------------------------------------\n",
    "\n",
    "# 6. æ¸…ç†å†…å­˜\n",
    "del df_train, train_data, val_data, X_train_copy, X_val_copy\n",
    "gc.collect()\n",
    "print(\"éªŒè¯é›†åˆ›å»ºå®Œæ¯•ï¼\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d3f3c0f-6e4d-41d2-b296-cd011402ec9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- åŸå§‹è®­ç»ƒé›† (X_train) åˆ†å¸ƒ ---\n",
      "Counter({4: 1461, 0: 30, 3: 21, 1: 19, 2: 14})\n",
      "\n",
      "'ticker_id' åœ¨ç‰¹å¾ä¸­çš„ç´¢å¼•ä¸º: 168\n",
      "\n",
      "æ­£åœ¨åº”ç”¨ SMOTENC (åªå¯¹è®­ç»ƒé›†)...\n",
      "(è¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿï¼Œå› ä¸ºå®ƒæ­£åœ¨ 'åˆ›é€ ' æ–°çš„åˆæˆæ ·æœ¬...)\n",
      "\n",
      "--- SMOTE (è¿‡é‡‡æ ·å) è®­ç»ƒé›†åˆ†å¸ƒ ---\n",
      "Counter({4: 1461, 0: 1461, 3: 1461, 2: 1461, 1: 1461})\n",
      "åŸå§‹ X_train å½¢çŠ¶: (1545, 300)\n",
      "SMOTE å X_train_smote å½¢çŠ¶: (7305, 300)\n"
     ]
    }
   ],
   "source": [
    "print(\"--- åŸå§‹è®­ç»ƒé›† (X_train) åˆ†å¸ƒ ---\")\n",
    "print(Counter(y_train))\n",
    "\n",
    "# 1. æ‰¾åˆ° 'ticker_id' çš„åˆ—ç´¢å¼•\n",
    "# SMOTENC éœ€è¦çŸ¥é“å“ªä¸€åˆ—æ˜¯ç±»åˆ«ç‰¹å¾\n",
    "try:\n",
    "    categorical_feature_index = [X_train.columns.get_loc('ticker_id')]\n",
    "    print(f\"\\n'ticker_id' åœ¨ç‰¹å¾ä¸­çš„ç´¢å¼•ä¸º: {categorical_feature_index[0]}\")\n",
    "except KeyError:\n",
    "    print(\"\\né”™è¯¯ï¼š'ticker_id' ä¸åœ¨ X_train çš„åˆ—ä¸­ï¼\")\n",
    "    raise\n",
    "# 2. å®šä¹‰ SMOTENC ç­–ç•¥\n",
    "# 'sampling_strategy'='auto' (æˆ– 'not majority') \n",
    "# å°†æŠŠæ‰€æœ‰ç¨€æœ‰ç±» (0,1,2,3) çš„æ ·æœ¬æ•°é‡æå‡åˆ°ä¸å¤šæ•°ç±» (4) ç›¸åŒ\n",
    "smote_nc = SMOTENC(\n",
    "    sampling_strategy='auto',\n",
    "    categorical_features=categorical_feature_index,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"\\næ­£åœ¨åº”ç”¨ SMOTENC (åªå¯¹è®­ç»ƒé›†)...\")\n",
    "print(\"(è¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿï¼Œå› ä¸ºå®ƒæ­£åœ¨ 'åˆ›é€ ' æ–°çš„åˆæˆæ ·æœ¬...)\")\n",
    "X_train_smote, y_train_smote = smote_nc.fit_resample(X_train, y_train)\n",
    "\n",
    "# 3. æ£€æŸ¥æ–°çš„å¹³è¡¡ååˆ†å¸ƒ\n",
    "print(\"\\n--- SMOTE (è¿‡é‡‡æ ·å) è®­ç»ƒé›†åˆ†å¸ƒ ---\")\n",
    "print(Counter(y_train_smote))\n",
    "print(f\"åŸå§‹ X_train å½¢çŠ¶: {X_train.shape}\")\n",
    "print(f\"SMOTE å X_train_smote å½¢çŠ¶: {X_train_smote.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e0662b0-b3fa-4cd6-b712-ea099aee8712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å¼€å§‹è®­ç»ƒ Model v6 (ä½¿ç”¨ SMOTE æ•°æ®)...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008154 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17054\n",
      "[LightGBM] [Info] Number of data points in the train set: 7305, number of used features: 276\n",
      "[LightGBM] [Info] Start training from score -1.609438\n",
      "[LightGBM] [Info] Start training from score -1.609438\n",
      "[LightGBM] [Info] Start training from score -1.609438\n",
      "[LightGBM] [Info] Start training from score -1.609438\n",
      "[LightGBM] [Info] Start training from score -1.609438\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[55]\tvalid_0's multi_logloss: 0.380834\n",
      "Model v6 è®­ç»ƒå®Œæˆï¼\n"
     ]
    }
   ],
   "source": [
    "# 1. å®šä¹‰ LightGBM æ¨¡å‹å‚æ•°\n",
    "lgb_params = {\n",
    "    'objective': 'multiclass',\n",
    "    'num_class': 5,\n",
    "    'metric': 'multi_logloss',\n",
    "    'n_estimators': 500,\n",
    "    'learning_rate': 0.05,\n",
    "    'n_jobs': -1,\n",
    "    'seed': 42,\n",
    "    # ç§»é™¤ 'class_weight': 'balanced'\n",
    "}\n",
    "\n",
    "# 2. åˆå§‹åŒ–æ¨¡å‹\n",
    "model_v6 = lgb.LGBMClassifier(**lgb_params)\n",
    "\n",
    "# 3. è®­ç»ƒæ¨¡å‹\n",
    "print(f\"å¼€å§‹è®­ç»ƒ Model v6 (ä½¿ç”¨ SMOTE æ•°æ®)...\")\n",
    "# (æ³¨æ„ï¼šX_val ä»ç„¶æ˜¯åŸå§‹çš„ã€æœªé‡‡æ ·çš„ 300 ç‰¹å¾éªŒè¯é›†)\n",
    "model_v6.fit(\n",
    "    X_train_smote, y_train_smote,        # ğŸ‘ˆ ä½¿ç”¨ SMOTE åçš„æ•°æ®\n",
    "    eval_set=[(X_val, y_val)],            # ğŸ‘ˆ è¯„ä¼°ä»ä½¿ç”¨ *åŸå§‹* éªŒè¯é›†\n",
    "    eval_metric='multi_logloss',\n",
    "    callbacks=[lgb.early_stopping(50)],\n",
    "    categorical_feature=['ticker_id']\n",
    ")\n",
    "\n",
    "print(\"Model v6 è®­ç»ƒå®Œæˆï¼\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e06ed6cc-9caa-4b6c-9828-ff8e38595892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ­£åœ¨éªŒè¯é›†ä¸Šè¿›è¡Œé¢„æµ‹...\n",
      "\n",
      "========================================\n",
      "ğŸ“ˆ Model v6 (SMOTE) Macro F1-Score: 0.1917\n",
      "----------------------------------------\n",
      "ğŸ“ˆ Model v2 (All Features) Macro F1-Score: 0.2238\n",
      "ğŸ“ˆ Model v4 (Undersampled 1:1) F1: 0.2250\n",
      "ğŸ“‰ Model v5 (Undersampled 1:10) F1: 0.1925\n",
      "ğŸ“‰ Model v3 (Top 300) F1: 0.1916\n",
      "ğŸ“‰ Baseline F1: 0.1905\n",
      "========================================\n",
      "ğŸš€ V6 vs V2 (Best) æ€§èƒ½æå‡: -0.0321\n",
      "========================================\n",
      "\n",
      "è¯¦ç»†åˆ†ç±»æŠ¥å‘Š (Model v6):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          HH       0.00      0.00      0.00        10\n",
      "          HL       0.00      0.00      0.00         9\n",
      "          LH       0.00      0.00      0.00         4\n",
      "          LL       0.00      0.00      0.00         5\n",
      "        None       0.93      0.99      0.96       359\n",
      "\n",
      "    accuracy                           0.92       387\n",
      "   macro avg       0.19      0.20      0.19       387\n",
      "weighted avg       0.86      0.92      0.89       387\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. åœ¨éªŒè¯é›†ä¸Šè¿›è¡Œé¢„æµ‹\n",
    "print(\"æ­£åœ¨éªŒè¯é›†ä¸Šè¿›è¡Œé¢„æµ‹...\")\n",
    "val_preds = model_v6.predict(X_val)\n",
    "\n",
    "# 2. è®¡ç®— Macro F1-Score\n",
    "macro_f1_v6 = f1_score(y_val, val_preds, average='macro', zero_division=0)\n",
    "\n",
    "print(\"\\n========================================\")\n",
    "print(f\"ğŸ“ˆ Model v6 (SMOTE) Macro F1-Score: {macro_f1_v6:.4f}\")\n",
    "print(\"----------------------------------------\")\n",
    "print(f\"ğŸ“ˆ Model v2 (All Features) Macro F1-Score: 0.2238\")\n",
    "print(f\"ğŸ“ˆ Model v4 (Undersampled 1:1) F1: 0.2250\")\n",
    "print(f\"ğŸ“‰ Model v5 (Undersampled 1:10) F1: 0.1925\")\n",
    "print(f\"ğŸ“‰ Model v3 (Top 300) F1: 0.1916\")\n",
    "print(f\"ğŸ“‰ Baseline F1: 0.1905\")\n",
    "print(\"========================================\")\n",
    "print(f\"ğŸš€ V6 vs V2 (Best) æ€§èƒ½æå‡: {macro_f1_v6 - 0.2238:.4f}\")\n",
    "print(\"========================================\")\n",
    "\n",
    "# 3. æ‰“å°è¯¦ç»†çš„åˆ†ç±»æŠ¥å‘Š\n",
    "target_map_full = {'HH': 0, 'HL': 1, 'LH': 2, 'LL': 3, 'None': 4}\n",
    "target_names = [key for key, val in sorted(target_map_full.items(), key=lambda item: item[1])]\n",
    "all_labels = [val for key, val in sorted(target_map_full.items(), key=lambda item: item[1])]\n",
    "\n",
    "print(\"\\nè¯¦ç»†åˆ†ç±»æŠ¥å‘Š (Model v6):\")\n",
    "print(classification_report(\n",
    "    y_val, \n",
    "    val_preds, \n",
    "    target_names=target_names, \n",
    "    labels=all_labels,\n",
    "    zero_division=0\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59d46ad-f6fa-493a-a560-d8acd2868b8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
