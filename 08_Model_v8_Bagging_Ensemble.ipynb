{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a2e4019-e7c5-454d-a723-562e354c2bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "åº“å¯¼å…¥å®Œæˆã€‚\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from collections import Counter\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# è®¾ç½®æ ·å¼\n",
    "sns.set(style='whitegrid')\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "print(\"åº“å¯¼å…¥å®Œæˆã€‚\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2013c4f8-705e-4f2c-b3f2-3c0333bbf5a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "åŠ è½½ train_with_features.csv...\n",
      "æ¢å¤æ•°æ®ç±»å‹...\n",
      "æ•°æ®åŠ è½½å®Œæˆã€‚\n"
     ]
    }
   ],
   "source": [
    "# 1. åŠ è½½æ•°æ®\n",
    "print(\"åŠ è½½ train_with_features.csv...\")\n",
    "try:\n",
    "    df_train = pd.read_csv('train_with_features.csv', low_memory=False)\n",
    "except FileNotFoundError:\n",
    "    print(\"é”™è¯¯ï¼šè¯·ç¡®ä¿ train_with_features.csv å­˜åœ¨ï¼\")\n",
    "    raise\n",
    "    # 2. æ¢å¤æ•°æ®ç±»å‹\n",
    "print(\"æ¢å¤æ•°æ®ç±»å‹...\")\n",
    "df_train['t'] = pd.to_datetime(df_train['t'])\n",
    "df_train['ticker_id'] = df_train['ticker_id'].astype('category')\n",
    "\n",
    "# 3. ç›®æ ‡ç¼–ç  (5ç±»)\n",
    "target_map = {'HH': 0, 'HL': 1, 'LH': 2, 'LL': 3}\n",
    "df_train['class_label_encoded'] = df_train['class_label'].map(target_map).fillna(4).astype(int)\n",
    "\n",
    "print(\"æ•°æ®åŠ è½½å®Œæˆã€‚\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd21bdc9-134c-4e75-9feb-d84724d50dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æŒ‰æ—¶é—´åˆ†å‰²æ•°æ®...\n",
      "ä¿®å¤æ•°å€¼åˆ—ç±»å‹å¹¶å¡«å…… NaN...\n",
      "è®­ç»ƒé›†å½¢çŠ¶: (1545, 68732)\n",
      "éªŒè¯é›†å½¢çŠ¶: (387, 68732)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. å®šä¹‰ç‰¹å¾\n",
    "TARGET = 'class_label_encoded'\n",
    "METADATA_COLS = ['class_label', 'class_label_encoded', 't', 'id', 'train_id']\n",
    "features_to_drop = [col for col in METADATA_COLS if col in df_train.columns]\n",
    "FEATURES = df_train.columns.drop(features_to_drop).tolist()\n",
    "\n",
    "# 2. æ—¶é—´åºåˆ—åˆ†å‰² (80/20)\n",
    "print(\"æŒ‰æ—¶é—´åˆ†å‰²æ•°æ®...\")\n",
    "df_train = df_train.sort_values(by=['t', 'ticker_id']).reset_index(drop=True)\n",
    "split_index = int(len(df_train) * 0.8)\n",
    "\n",
    "train_data = df_train.iloc[:split_index]\n",
    "val_data = df_train.iloc[split_index:]\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# ğŸ’¡ ã€å…³é”®ä¿®æ”¹ã€‘ æ·»åŠ  .copy()\n",
    "# è¿™å‘Šè¯‰ Pandasï¼šæˆ‘ä»¬è¦å»ºç«‹ä¸€ä¸ªå…¨æ–°çš„ç‹¬ç«‹å¯¹è±¡ï¼Œ\n",
    "# ä¹‹åæ— è®ºæ€ä¹ˆä¿®æ”¹ X_trainï¼Œéƒ½ä¸åŸå§‹çš„ df_train æ— å…³ã€‚\n",
    "# -------------------------------------------------------\n",
    "X_train = train_data[FEATURES].copy()\n",
    "y_train = train_data[TARGET].copy()\n",
    "X_val = val_data[FEATURES].copy()\n",
    "y_val = val_data[TARGET].copy()\n",
    "\n",
    "# 3. ä¿®å¤æ•°æ®ç±»å‹ (å…³é”®æ­¥éª¤ï¼)\n",
    "print(\"ä¿®å¤æ•°å€¼åˆ—ç±»å‹å¹¶å¡«å…… NaN...\")\n",
    "numeric_features = [col for col in FEATURES if col != 'ticker_id']\n",
    "\n",
    "# è½¬æ¢ç±»å‹\n",
    "# (ä½¿ç”¨ .copy() åï¼Œè¿™é‡Œçš„è­¦å‘Šåº”è¯¥ä¼šæ¶ˆå¤±)\n",
    "for col in numeric_features:\n",
    "    X_train[col] = pd.to_numeric(X_train[col], errors='coerce', downcast='float')\n",
    "    X_val[col] = pd.to_numeric(X_val[col], errors='coerce', downcast='float')\n",
    "\n",
    "# å¡«å…… NaN (ä»…æ•°å€¼åˆ—)\n",
    "X_train[numeric_features] = X_train[numeric_features].fillna(-999)\n",
    "X_val[numeric_features] = X_val[numeric_features].fillna(-999)\n",
    "\n",
    "print(f\"è®­ç»ƒé›†å½¢çŠ¶: {X_train.shape}\")\n",
    "print(f\"éªŒè¯é›†å½¢çŠ¶: {X_val.shape}\")\n",
    "\n",
    "# æ¸…ç†å†…å­˜\n",
    "del df_train, train_data, val_data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57d964b7-d5a9-4f66-acaf-4c2c9fcb4dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Bagging ç­–ç•¥ ---\n",
      "ç¨€æœ‰ä¿¡å·æ€»æ•°: 84\n",
      "æ¯ä¸ª Batch ä¸­ 'None' çš„æ•°é‡: 252 (æ¯”ä¾‹ 1:3)\n",
      "æ¯ä¸ª Batch æ€»å¤§å°: ~336\n",
      "å°†è®­ç»ƒ 10 ä¸ªæ¨¡å‹è¿›è¡Œé›†æˆ...\n",
      "\n",
      ">>> æ­£åœ¨è®­ç»ƒæ¨¡å‹ 1/10 ...\n",
      "\n",
      ">>> æ­£åœ¨è®­ç»ƒæ¨¡å‹ 2/10 ...\n",
      "\n",
      ">>> æ­£åœ¨è®­ç»ƒæ¨¡å‹ 3/10 ...\n",
      "\n",
      ">>> æ­£åœ¨è®­ç»ƒæ¨¡å‹ 4/10 ...\n",
      "\n",
      ">>> æ­£åœ¨è®­ç»ƒæ¨¡å‹ 5/10 ...\n",
      "\n",
      ">>> æ­£åœ¨è®­ç»ƒæ¨¡å‹ 6/10 ...\n",
      "\n",
      ">>> æ­£åœ¨è®­ç»ƒæ¨¡å‹ 7/10 ...\n",
      "\n",
      ">>> æ­£åœ¨è®­ç»ƒæ¨¡å‹ 8/10 ...\n",
      "\n",
      ">>> æ­£åœ¨è®­ç»ƒæ¨¡å‹ 9/10 ...\n",
      "\n",
      ">>> æ­£åœ¨è®­ç»ƒæ¨¡å‹ 10/10 ...\n",
      "\n",
      "æˆåŠŸè®­ç»ƒäº† 10 ä¸ªæ¨¡å‹ï¼\n"
     ]
    }
   ],
   "source": [
    "# ====================================================# é…ç½®é›†æˆå‚æ•°# ====================================================\n",
    "N_MODELS = 10           # è®­ç»ƒ 10 ä¸ªä¸åŒçš„æ¨¡å‹ (Batch æ•°é‡)\n",
    "NONE_RATIO = 3          # å™ªå£°:ä¿¡å· = 3:1 (æ¯” V4 çš„ 1:1 æ¸©å’Œï¼Œæ¯” V5 çš„ 10:1 æ¿€è¿›)\n",
    "# 1. è®¡ç®—ç¨€æœ‰ç±»æ•°é‡\n",
    "counts = Counter(y_train)\n",
    "n_minority = counts[0] + counts[1] + counts[2] + counts[3]\n",
    "n_none_target = int(n_minority * NONE_RATIO)\n",
    "\n",
    "# ç¡®ä¿ä¸è¶…è¿‡æ€»æ•°\n",
    "if n_none_target > counts[4]:\n",
    "    n_none_target = counts[4]\n",
    "\n",
    "print(f\"--- Bagging ç­–ç•¥ ---\")\n",
    "print(f\"ç¨€æœ‰ä¿¡å·æ€»æ•°: {n_minority}\")\n",
    "print(f\"æ¯ä¸ª Batch ä¸­ 'None' çš„æ•°é‡: {n_none_target} (æ¯”ä¾‹ 1:{NONE_RATIO})\")\n",
    "print(f\"æ¯ä¸ª Batch æ€»å¤§å°: ~{n_minority + n_none_target}\")\n",
    "print(f\"å°†è®­ç»ƒ {N_MODELS} ä¸ªæ¨¡å‹è¿›è¡Œé›†æˆ...\")\n",
    "\n",
    "# 2. è®­ç»ƒå¾ªç¯\n",
    "models = []\n",
    "\n",
    "for i in range(N_MODELS):\n",
    "    print(f\"\\n>>> æ­£åœ¨è®­ç»ƒæ¨¡å‹ {i+1}/{N_MODELS} ...\")\n",
    "    \n",
    "    # A. åˆ›å»º Batch (æ¬ é‡‡æ ·)\n",
    "    # å…³é”®ï¼šrandom_state=iï¼Œç¡®ä¿æ¯ä¸ªæ¨¡å‹çœ‹åˆ°çš„ 'None' æ ·æœ¬æ˜¯ä¸åŒçš„ï¼\n",
    "    sampling_strategy = {\n",
    "        0: counts[0], 1: counts[1], 2: counts[2], 3: counts[3], # ä¿ç•™æ‰€æœ‰ä¿¡å·\n",
    "        4: n_none_target  # é‡‡æ ·éƒ¨åˆ†å™ªå£°\n",
    "    }\n",
    "    rus = RandomUnderSampler(sampling_strategy=sampling_strategy, random_state=i)\n",
    "    X_batch, y_batch = rus.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # B. å®šä¹‰ LGBM æ¨¡å‹\n",
    "    # æ—¢ç„¶æ•°æ®é‡å°ï¼Œæˆ‘ä»¬å¢åŠ ä¸€ç‚¹æ­£åˆ™åŒ–é˜²æ­¢è¿‡æ‹Ÿåˆ\n",
    "    clf = lgb.LGBMClassifier(\n",
    "        objective='multiclass',\n",
    "        num_class=5,\n",
    "        n_estimators=300,      # å› ä¸ºæ•°æ®å°‘ï¼Œä¸éœ€è¦ 500 æ£µæ ‘\n",
    "        learning_rate=0.05,\n",
    "        num_leaves=31,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        verbose=-1\n",
    "    )\n",
    "    \n",
    "    # C. è®­ç»ƒ\n",
    "    clf.fit(\n",
    "        X_batch, y_batch,\n",
    "        categorical_feature=['ticker_id']\n",
    "    )\n",
    "    \n",
    "    models.append(clf)\n",
    "\n",
    "print(f\"\\næˆåŠŸè®­ç»ƒäº† {len(models)} ä¸ªæ¨¡å‹ï¼\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aba51f99-737f-4629-ad1a-0a81720a4a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å¼€å§‹é›†æˆé¢„æµ‹ (Soft Voting)...\n",
      "å·²æ±‡æ€»æ¨¡å‹ 2/10 çš„é¢„æµ‹...\n",
      "å·²æ±‡æ€»æ¨¡å‹ 4/10 çš„é¢„æµ‹...\n",
      "å·²æ±‡æ€»æ¨¡å‹ 6/10 çš„é¢„æµ‹...\n",
      "å·²æ±‡æ€»æ¨¡å‹ 8/10 çš„é¢„æµ‹...\n",
      "å·²æ±‡æ€»æ¨¡å‹ 10/10 çš„é¢„æµ‹...\n",
      "\n",
      "========================================\n",
      "ğŸ“ˆ Model v8 (Bagging Ensemble) Macro F1: 0.1919\n",
      "----------------------------------------\n",
      "Model v2 (Best Single): 0.2238\n",
      "Model v4 (Undersample): 0.2250 (Precision low)\n",
      "========================================\n",
      "\n",
      "è¯¦ç»†åˆ†ç±»æŠ¥å‘Š (é›†æˆæ¨¡å‹):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          HH       0.00      0.00      0.00        10\n",
      "          HL       0.00      0.00      0.00         9\n",
      "          LH       0.00      0.00      0.00         4\n",
      "          LL       0.00      0.00      0.00         5\n",
      "        None       0.93      0.99      0.96       359\n",
      "\n",
      "    accuracy                           0.92       387\n",
      "   macro avg       0.19      0.20      0.19       387\n",
      "weighted avg       0.86      0.92      0.89       387\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"å¼€å§‹é›†æˆé¢„æµ‹ (Soft Voting)...\")\n",
    "\n",
    "# åˆå§‹åŒ–æ¦‚ç‡çŸ©é˜µ (è¡Œæ•° x 5ç±»)\n",
    "sum_probs = np.zeros((len(X_val), 5))\n",
    "\n",
    "# 1. è®©æ¯ä¸ªæ¨¡å‹éƒ½è¿›è¡Œé¢„æµ‹ï¼Œå¹¶ç´¯åŠ æ¦‚ç‡\n",
    "for i, model in enumerate(models):\n",
    "    # predict_proba è¿”å›æ¯ä¸ªç±»çš„æ¦‚ç‡\n",
    "    probs = model.predict_proba(X_val)\n",
    "    sum_probs += probs\n",
    "    if (i+1) % 2 == 0:\n",
    "        print(f\"å·²æ±‡æ€»æ¨¡å‹ {i+1}/{N_MODELS} çš„é¢„æµ‹...\")\n",
    "\n",
    "# 2. å–å¹³å‡\n",
    "avg_probs = sum_probs / N_MODELS\n",
    "\n",
    "# 3. å–æœ€å¤§æ¦‚ç‡å¯¹åº”çš„ç±»åˆ«\n",
    "val_preds = np.argmax(avg_probs, axis=1)\n",
    "\n",
    "# 4. è¯„ä¼°\n",
    "macro_f1_v8 = f1_score(y_val, val_preds, average='macro', zero_division=0)\n",
    "\n",
    "print(\"\\n========================================\")\n",
    "print(f\"ğŸ“ˆ Model v8 (Bagging Ensemble) Macro F1: {macro_f1_v8:.4f}\")\n",
    "print(\"----------------------------------------\")\n",
    "print(f\"Model v2 (Best Single): 0.2238\")\n",
    "print(f\"Model v4 (Undersample): 0.2250 (Precision low)\")\n",
    "print(\"========================================\")\n",
    "\n",
    "# 5. è¯¦ç»†æŠ¥å‘Š\n",
    "target_names = ['HH', 'HL', 'LH', 'LL', 'None']\n",
    "print(\"\\nè¯¦ç»†åˆ†ç±»æŠ¥å‘Š (é›†æˆæ¨¡å‹):\")\n",
    "print(classification_report(\n",
    "    y_val, \n",
    "    val_preds, \n",
    "    target_names=target_names,\n",
    "    zero_division=0\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c36f1c3-381f-400a-968c-47b9a042bc36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681382ab-15bd-4230-b2fc-06b7346c92c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a10aeb-fc87-49c1-ab87-2a5dfada64d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
