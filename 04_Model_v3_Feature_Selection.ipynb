{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69bc5480-7d23-4be1-bafd-a30593e75d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "import gc # åƒåœ¾å›æ”¶\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# è®¾ç½® Matplotlib/Seaborn æ ·å¼\n",
    "sns.set(style='whitegrid')\n",
    "# è®¾ç½® Pandas æ˜¾ç¤ºé€‰é¡¹\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7713a954-2f0e-45f6-ab02-a3b2a4e90029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ­£åœ¨åŠ è½½ç‰¹å¾åŒ–è®­ç»ƒæ•°æ® (train_with_features.csv)...\n",
      "æ•°æ®åŠ è½½æˆåŠŸï¼å½¢çŠ¶: (1932, 68736)\n",
      "æ­£åœ¨æ¢å¤æ•°æ®ç±»å‹...\n",
      "æ•°æ®ç±»å‹æ¢å¤å®Œæ¯•ã€‚\n",
      "           t ticker_id class_label\n",
      "0 2023-04-03         1         NaN\n",
      "1 2023-04-05         1         NaN\n",
      "2 2023-04-06         1         NaN\n",
      "3 2023-04-11         1         NaN\n",
      "4 2023-04-12         1         NaN\n"
     ]
    }
   ],
   "source": [
    "print(\"æ­£åœ¨åŠ è½½ç‰¹å¾åŒ–è®­ç»ƒæ•°æ® (train_with_features.csv)...\")\n",
    "# è¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿï¼Œè¯·è€å¿ƒç­‰å¾…\n",
    "try:\n",
    "    df_train = pd.read_csv('train_with_features.csv', low_memory=False)\n",
    "    print(f\"æ•°æ®åŠ è½½æˆåŠŸï¼å½¢çŠ¶: {df_train.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"é”™è¯¯ï¼štrain_with_features.csv æ–‡ä»¶æœªæ‰¾åˆ°ã€‚\")\n",
    "    # å¦‚æœå‡ºé”™ï¼Œåœæ­¢æ‰§è¡Œ\n",
    "    raise\n",
    "\n",
    "# -----------------------------------------------------------------\n",
    "# å…³é”®ï¼šæ¢å¤æ•°æ®ç±»å‹ï¼ˆCSV ä¸¢å¤±äº†å®ƒä»¬ï¼‰\n",
    "# -----------------------------------------------------------------\n",
    "print(\"æ­£åœ¨æ¢å¤æ•°æ®ç±»å‹...\")\n",
    "# 1. æ¢å¤æ—¶é—´åˆ—\n",
    "df_train['t'] = pd.to_datetime(df_train['t'])\n",
    "\n",
    "# 2. æ¢å¤ ticker_id ä¸º 'category'\n",
    "# è¿™æ˜¯ LightGBM é«˜æ•ˆå¤„ç†æ‰€å¿…éœ€çš„\n",
    "df_train['ticker_id'] = df_train['ticker_id'].astype('category')\n",
    "\n",
    "print(\"æ•°æ®ç±»å‹æ¢å¤å®Œæ¯•ã€‚\")\n",
    "print(df_train[['t', 'ticker_id', 'class_label']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef94ba57-21c4-41ca-825a-7c45fda0fd4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ç›®æ ‡å˜é‡ç¼–ç å®Œæˆã€‚\n",
      "class_label_encoded\n",
      "0      40\n",
      "1      28\n",
      "2      18\n",
      "3      26\n",
      "4    1820\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 1. å®šä¹‰ 5 åˆ†ç±»ç›®æ ‡æ˜ å°„\n",
    "# (HH=0, HL=1, LH=2, LL=3, NaN=4)\n",
    "target_map = {\n",
    "    'HH': 0,\n",
    "    'HL': 1,\n",
    "    'LH': 2,\n",
    "    'LL': 3\n",
    "}\n",
    "# æˆ‘ä»¬å°† 'None' (å³ NaN) æ˜ å°„ä¸º 4\n",
    "\n",
    "# 2. æ˜ å°„\n",
    "df_train['class_label_encoded'] = df_train['class_label'].map(target_map)\n",
    "df_train['class_label_encoded'] = df_train['class_label_encoded'].fillna(4)\n",
    "df_train['class_label_encoded'] = df_train['class_label_encoded'].astype(int)\n",
    "\n",
    "print(\"ç›®æ ‡å˜é‡ç¼–ç å®Œæˆã€‚\")\n",
    "print(df_train['class_label_encoded'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b753d1db-3e81-49eb-808d-1620d57b8a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model v3 ç‰¹å¾é€‰æ‹© ---\n",
      "å·²åŠ è½½ 300 ä¸ª Top ç‰¹å¾ (Top 300 + 'ticker_id')ã€‚\n"
     ]
    }
   ],
   "source": [
    "# 1. å®šä¹‰ç›®æ ‡å’Œå…ƒæ•°æ®\n",
    "TARGET = 'class_label_encoded'\n",
    "METADATA_COLS = ['class_label', 'class_label_encoded', 't', 'id', 'train_id']\n",
    "\n",
    "# 2. åŠ è½½ V2 æ¨¡å‹çš„ç‰¹å¾é‡è¦æ€§\n",
    "try:\n",
    "    importance_df = pd.read_csv('feature_importance_v2.csv')\n",
    "except FileNotFoundError:\n",
    "    print(\"é”™è¯¯ï¼š'feature_importance_v2.csv' æœªæ‰¾åˆ°ï¼\")\n",
    "    print(\"è¯·å…ˆè¿”å› 03_Model_v2... ç¬”è®°æœ¬ï¼Œè¿è¡Œ CELL 8 ä»¥ä¿å­˜è¯¥æ–‡ä»¶ã€‚\")\n",
    "    raise\n",
    "\n",
    "# 3. å®šä¹‰æˆ‘ä»¬çš„â€œç²¾è‹±ç‰¹å¾é›†â€\n",
    "# -----------------------------------------------\n",
    "NUM_TOP_FEATURES = 300  # è¿™æ˜¯ä¸€ä¸ªè¶…å‚æ•°ï¼Œæˆ‘ä»¬å¯ä»¥è°ƒæ•´å®ƒ (ä¾‹å¦‚ 200, 300, 500)\n",
    "# -----------------------------------------------\n",
    "\n",
    "# 4. è·å– Top N ç‰¹å¾çš„åˆ—è¡¨\n",
    "top_features = importance_df.head(NUM_TOP_FEATURES)['feature'].tolist()\n",
    "\n",
    "# 5. ç¡®ä¿ 'ticker_id' è¢«åŒ…å«åœ¨å†…ï¼\n",
    "# (å³ä½¿å®ƒé‡è¦æ€§ä¸é«˜ï¼Œå®ƒå¯¹æ¨¡å‹ç»“æ„ä¹Ÿè‡³å…³é‡è¦)\n",
    "if 'ticker_id' not in top_features:\n",
    "    top_features.append('ticker_id')\n",
    "\n",
    "# 6. å°†æ­¤åˆ—è¡¨è®¾ç½®ä¸ºæˆ‘ä»¬çš„æœ€ç»ˆ FEATURES\n",
    "FEATURES = top_features\n",
    "\n",
    "print(f\"--- Model v3 ç‰¹å¾é€‰æ‹© ---\")\n",
    "print(f\"å·²åŠ è½½ {len(FEATURES)} ä¸ª Top ç‰¹å¾ (Top {NUM_TOP_FEATURES} + 'ticker_id')ã€‚\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c12587f0-f8df-4e62-bbb3-4d8d3602ff6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ­£åœ¨æŒ‰ 't' å’Œ 'ticker_id' æ’åºæ•°æ®ä»¥è¿›è¡ŒéªŒè¯åˆ†å‰²...\n",
      "æ€»è®­ç»ƒæ ·æœ¬æ•°: 1932\n",
      "æ–°è®­ç»ƒé›†æ ·æœ¬æ•°: 1545\n",
      "æ–°éªŒè¯é›†æ ·æœ¬æ•°: 387\n",
      "éªŒè¯é›†æ—¶é—´èŒƒå›´: 2024-09-20 00:00:00 åˆ° 2025-01-31 00:00:00\n",
      "æ­£åœ¨ä¿®å¤ 'object' æ•°æ®ç±»å‹...\n",
      "å·²å°† 299 ä¸ªç‰¹å¾åˆ—å¼ºåˆ¶è½¬æ¢ä¸ºæ•°å€¼ç±»å‹ã€‚\n",
      "æ—¶é—´åºåˆ—éªŒè¯é›†åˆ›å»ºå®Œæ¯•ï¼\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------------# å•å…ƒæ ¼ 5ï¼šå»ºç«‹æ—¶é—´åºåˆ—éªŒè¯æ¡†æ¶ (TSV) + ç±»å‹ä¿®å¤# -----------------------------------------------------------------\n",
    "# 1. ç¡®ä¿æ•°æ®ä¸¥æ ¼æŒ‰ *åŸå§‹* åŸºçº¿çš„æ–¹å¼æ’åº\n",
    "print(\"æ­£åœ¨æŒ‰ 't' å’Œ 'ticker_id' æ’åºæ•°æ®ä»¥è¿›è¡ŒéªŒè¯åˆ†å‰²...\")\n",
    "# æ³¨æ„ï¼šç¡®ä¿ df_train åœ¨è¿™é‡Œä»ç„¶æ˜¯æ‚¨åœ¨ CELL 2 ä¸­åŠ è½½çš„å®Œæ•´æ•°æ®\n",
    "df_train = df_train.sort_values(by=['t', 'ticker_id']).reset_index(drop=True)\n",
    "\n",
    "# 2. å®šä¹‰åˆ†å‰²ç‚¹ (ä¸åŸºçº¿å®Œå…¨ä¸€è‡´)\n",
    "split_percentage = 0.8\n",
    "split_index = int(len(df_train) * split_percentage)\n",
    "\n",
    "# 3. åˆ†å‰²æ•°æ®\n",
    "train_data = df_train.iloc[:split_index]\n",
    "val_data = df_train.iloc[split_index:]\n",
    "\n",
    "print(f\"æ€»è®­ç»ƒæ ·æœ¬æ•°: {len(df_train)}\")\n",
    "print(f\"æ–°è®­ç»ƒé›†æ ·æœ¬æ•°: {len(train_data)}\")\n",
    "print(f\"æ–°éªŒè¯é›†æ ·æœ¬æ•°: {len(val_data)}\")\n",
    "print(f\"éªŒè¯é›†æ—¶é—´èŒƒå›´: {val_data['t'].min()} åˆ° {val_data['t'].max()}\")\n",
    "\n",
    "# 4. åˆ›å»º X (ç‰¹å¾) å’Œ y (ç›®æ ‡)# FEATURES åˆ—è¡¨åº”è¯¥å·²ç»åœ¨æ‚¨ä¸Šä¸€ä¸ªå•å…ƒæ ¼ (CELL 4) ä¸­å®šä¹‰äº†\n",
    "X_train = train_data[FEATURES]\n",
    "y_train = train_data[TARGET]\n",
    "\n",
    "X_val = val_data[FEATURES]\n",
    "y_val = val_data[TARGET]\n",
    "\n",
    "# -----------------------------------------------------------------# ğŸ’¡ ã€é”™è¯¯ä¿®å¤ã€‘ å¼ºåˆ¶è½¬æ¢æ•°æ®ç±»å‹# -----------------------------------------------------------------\n",
    "print(\"æ­£åœ¨ä¿®å¤ 'object' æ•°æ®ç±»å‹...\")\n",
    "\n",
    "# æ‰¾å‡º 'ticker_id' ä¹‹å¤–çš„æ‰€æœ‰ç‰¹å¾åˆ—\n",
    "numeric_features = [col for col in FEATURES if col != 'ticker_id']\n",
    "\n",
    "# æˆ‘ä»¬ä½¿ç”¨ .copy() æ¥é¿å… Pandas çš„ SettingWithCopyWarning\n",
    "X_train_copy = X_train.copy()\n",
    "X_val_copy = X_val.copy()\n",
    "\n",
    "for col in numeric_features:\n",
    "    X_train_copy[col] = pd.to_numeric(X_train_copy[col], errors='coerce', downcast='float')\n",
    "    X_val_copy[col] = pd.to_numeric(X_val_copy[col], errors='coerce', downcast='float')\n",
    "\n",
    "# æ›¿æ¢å›åŸæ¥çš„å˜é‡\n",
    "X_train = X_train_copy\n",
    "X_val = X_val_copy\n",
    "\n",
    "print(f\"å·²å°† {len(numeric_features)} ä¸ªç‰¹å¾åˆ—å¼ºåˆ¶è½¬æ¢ä¸ºæ•°å€¼ç±»å‹ã€‚\")\n",
    "# -----------------------------------------------------------------# 5. æ¸…ç†å†…å­˜del df_train, train_data, val_data, X_train_copy, X_val_copy\n",
    "gc.collect()\n",
    "\n",
    "print(\"æ—¶é—´åºåˆ—éªŒè¯é›†åˆ›å»ºå®Œæ¯•ï¼\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a160c8c2-c5d2-4318-84aa-a810311b36ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å¼€å§‹è®­ç»ƒ Model v3 (ä½¿ç”¨ Top 300 ç‰¹å¾)...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004675 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13692\n",
      "[LightGBM] [Info] Number of data points in the train set: 1545, number of used features: 276\n",
      "[LightGBM] [Info] Start training from score -1.609438\n",
      "[LightGBM] [Info] Start training from score -1.609438\n",
      "[LightGBM] [Info] Start training from score -1.609438\n",
      "[LightGBM] [Info] Start training from score -1.609438\n",
      "[LightGBM] [Info] Start training from score -1.609438\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[64]\tvalid_0's multi_logloss: 0.420834\n",
      "Model v3 è®­ç»ƒå®Œæˆï¼\n"
     ]
    }
   ],
   "source": [
    "# 1. å®šä¹‰ LightGBM æ¨¡å‹å‚æ•° (ä¸ V2 ç›¸åŒ)\n",
    "lgb_params = {\n",
    "    'objective': 'multiclass',\n",
    "    'num_class': 5,\n",
    "    'metric': 'multi_logloss',\n",
    "    'n_estimators': 500,\n",
    "    'learning_rate': 0.05,\n",
    "    'n_jobs': -1,\n",
    "    'seed': 42,\n",
    "    'class_weight': 'balanced'\n",
    "}\n",
    "\n",
    "# 2. åˆå§‹åŒ–æ¨¡å‹\n",
    "model_v3 = lgb.LGBMClassifier(**lgb_params)\n",
    "\n",
    "# 3. è®­ç»ƒæ¨¡å‹\n",
    "print(f\"å¼€å§‹è®­ç»ƒ Model v3 (ä½¿ç”¨ Top {len(FEATURES)} ç‰¹å¾)...\")\n",
    "model_v3.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    eval_metric='multi_logloss',\n",
    "    callbacks=[lgb.early_stopping(50)],\n",
    "    categorical_feature=['ticker_id'] # å¿…é¡»æŒ‡å®š\n",
    ")\n",
    "\n",
    "print(\"Model v3 è®­ç»ƒå®Œæˆï¼\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e973de5-bf16-4cd1-8ca4-a1342fb809f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ­£åœ¨éªŒè¯é›†ä¸Šè¿›è¡Œé¢„æµ‹...\n",
      "\n",
      "========================================\n",
      "ğŸ“ˆ Model v3 (Top 300) Macro F1-Score: 0.1916\n",
      "ğŸ“ˆ Model v2 (All Features) Macro F1-Score: 0.2238\n",
      "ğŸ“‰ Baseline Macro F1-Score: 0.1905\n",
      "========================================\n",
      "ğŸš€ V3 vs V2 æ€§èƒ½æå‡: -0.0322\n",
      "========================================\n",
      "\n",
      "è¯¦ç»†åˆ†ç±»æŠ¥å‘Š (Model v3):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          HH       0.00      0.00      0.00        10\n",
      "          HL       0.00      0.00      0.00         9\n",
      "          LH       0.00      0.00      0.00         4\n",
      "          LL       0.00      0.00      0.00         5\n",
      "        None       0.93      0.99      0.96       359\n",
      "\n",
      "    accuracy                           0.92       387\n",
      "   macro avg       0.19      0.20      0.19       387\n",
      "weighted avg       0.86      0.92      0.89       387\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. åœ¨éªŒè¯é›†ä¸Šè¿›è¡Œé¢„æµ‹\n",
    "print(\"æ­£åœ¨éªŒè¯é›†ä¸Šè¿›è¡Œé¢„æµ‹...\")\n",
    "val_preds = model_v3.predict(X_val)\n",
    "\n",
    "# 2. è®¡ç®— Macro F1-Score\n",
    "macro_f1_v3 = f1_score(y_val, val_preds, average='macro', zero_division=0)\n",
    "\n",
    "print(\"\\n========================================\")\n",
    "print(f\"ğŸ“ˆ Model v3 (Top {NUM_TOP_FEATURES}) Macro F1-Score: {macro_f1_v3:.4f}\")\n",
    "print(f\"ğŸ“ˆ Model v2 (All Features) Macro F1-Score: 0.2238\")\n",
    "print(f\"ğŸ“‰ Baseline Macro F1-Score: 0.1905\")\n",
    "print(\"========================================\")\n",
    "print(f\"ğŸš€ V3 vs V2 æ€§èƒ½æå‡: {macro_f1_v3 - 0.2238:.4f}\")\n",
    "print(\"========================================\")\n",
    "\n",
    "# 3. æ‰“å°è¯¦ç»†çš„åˆ†ç±»æŠ¥å‘Š\n",
    "target_map_full = {'HH': 0, 'HL': 1, 'LH': 2, 'LL': 3, 'None': 4}\n",
    "target_names = [key for key, val in sorted(target_map_full.items(), key=lambda item: item[1])]\n",
    "all_labels = [val for key, val in sorted(target_map_full.items(), key=lambda item: item[1])]\n",
    "\n",
    "print(\"\\nè¯¦ç»†åˆ†ç±»æŠ¥å‘Š (Model v3):\")\n",
    "print(classification_report(\n",
    "    y_val, \n",
    "    val_preds, \n",
    "    target_names=target_names, \n",
    "    labels=all_labels,\n",
    "    zero_division=0\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050b05bc-2bca-4fa6-ae06-9e21366dae4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12f49f2-bfaf-4679-9ed0-2c3e33168562",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f93223-0d87-4d2f-8a59-5918d5fc57e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44579af4-0beb-4f69-b35b-12f2894d63c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
